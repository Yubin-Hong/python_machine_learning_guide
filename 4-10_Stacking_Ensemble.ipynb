{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking: Aggregate multiple algorithms to make prediction.(Similar to Bagging & Boosting). But the biggest difference is that stacking use prediction data for next prediction.  \n",
    "Make each algorithm's prediction dataset into final matadata set. And then with this matadata set, use another ML algorithm for final training.(aka. meta model)  \n",
    "Stacking model need two type of model. Individual base models and final meta model.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base of Stacking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "X_features = cancer_data.data\n",
    "y_target = cancer_data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN model: 0.9210526315789473\n",
      "Accuracy of RandomForest model: 0.9736842105263158\n",
      "Accuracy of DecisionTree model: 0.9385964912280702\n",
      "Accuracy of AdaBoost model: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# Individual Base Models\n",
    "KNN = KNeighborsClassifier(n_neighbors=4)\n",
    "RF = RandomForestClassifier(n_estimators=100)\n",
    "DT = DecisionTreeClassifier()\n",
    "AdaBoost = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "KNN.fit(X_train, y_train)\n",
    "RF.fit(X_train, y_train)\n",
    "DT.fit(X_train, y_train)\n",
    "AdaBoost.fit(X_train, y_train)\n",
    "\n",
    "KNN_pred = KNN.predict(X_test)\n",
    "RF_pred = RF.predict(X_test)\n",
    "DT_pred = DT.predict(X_test)\n",
    "AdaBoost_pred = AdaBoost.predict(X_test)\n",
    "\n",
    "KNN_acc = accuracy_score(y_test, KNN_pred)\n",
    "RF_acc = accuracy_score(y_test, RF_pred)\n",
    "DT_acc = accuracy_score(y_test, DT_pred)\n",
    "AdaBoost_acc = accuracy_score(y_test, AdaBoost_pred)\n",
    "\n",
    "print('Accuracy of KNN model: {}'.format(KNN_acc))\n",
    "print('Accuracy of RandomForest model: {}'.format(RF_acc))\n",
    "print('Accuracy of DecisionTree model: {}'.format(DT_acc))\n",
    "print('Accuracy of AdaBoost model: {}'.format(AdaBoost_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 114)\n",
      "(114, 4)\n"
     ]
    }
   ],
   "source": [
    "# Make Prediction Matrix\n",
    "pred_M = np.array([KNN_pred, RF_pred, DT_pred, AdaBoost_pred])\n",
    "print(pred_M.shape)\n",
    "\n",
    "# Use np.transpose to fit\n",
    "pred = np.transpose(pred_M)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Final Meta Model: 0.9649\n"
     ]
    }
   ],
   "source": [
    "# Meta Model using LogisticRegression\n",
    "LR_final = LogisticRegression(C=10)\n",
    "LR_final.fit(pred, y_test)\n",
    "final_pred = LR_final.predict(pred)\n",
    "final_acc = accuracy_score(y_test, final_pred)\n",
    "\n",
    "print('Accuracy of Final Meta Model: {:.4f}'.format(final_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV set base Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# In individual base model, make train/test data for meta model\n",
    "def get_stacking_base_datasets(model, X_train, y_train, X_test, n_folds):\n",
    "    KF = KFold(n_splits=n_folds, shuffle=False)\n",
    "    \n",
    "    # Initialization of data for meta model\n",
    "    train_fold_pred = np.zeros((X_train.shape[0], 1))   #train_pred from KFold\n",
    "    test_pred = np.zeros((X_test.shape[0], n_folds))    #test_pred\n",
    "    print(model.__class__.__name__, 'model starts...')\n",
    "    \n",
    "    #Start CV\n",
    "    for folder_counter, (train_index, valid_index) in enumerate(KF.split(X_train)):\n",
    "        print('#{} fold set'.format(folder_counter))\n",
    "        X_tr = X_train[train_index]     #train features\n",
    "        y_tr = y_train[train_index]     #train labels\n",
    "        X_va = X_train[valid_index]     #validation features\n",
    "\n",
    "        model.fit(X_tr, y_tr)           #Training...\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_va).reshape(-1,1) #Input prediction of validation data\n",
    "        test_pred[:, folder_counter] = model.predict(X_test)                #Input prediction of test data\n",
    "\n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)               #Average prediction of test data\n",
    "\n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier model starts...\n",
      "#0 fold set\n",
      "#1 fold set\n",
      "#2 fold set\n",
      "#3 fold set\n",
      "#4 fold set\n",
      "#5 fold set\n",
      "#6 fold set\n",
      "RandomForestClassifier model starts...\n",
      "#0 fold set\n",
      "#1 fold set\n",
      "#2 fold set\n",
      "#3 fold set\n",
      "#4 fold set\n",
      "#5 fold set\n",
      "#6 fold set\n",
      "DecisionTreeClassifier model starts...\n",
      "#0 fold set\n",
      "#1 fold set\n",
      "#2 fold set\n",
      "#3 fold set\n",
      "#4 fold set\n",
      "#5 fold set\n",
      "#6 fold set\n",
      "AdaBoostClassifier model starts...\n",
      "#0 fold set\n",
      "#1 fold set\n",
      "#2 fold set\n",
      "#3 fold set\n",
      "#4 fold set\n",
      "#5 fold set\n",
      "#6 fold set\n"
     ]
    }
   ],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=4)\n",
    "RF = RandomForestClassifier(n_estimators=100)\n",
    "DT = DecisionTreeClassifier()\n",
    "AdaBoost = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "knn_train, knn_test = get_stacking_base_datasets(KNN, X_train, y_train, X_test, 7)\n",
    "rf_train, rf_test = get_stacking_base_datasets(RF, X_train, y_train, X_test, 7)\n",
    "dt_train, dt_test = get_stacking_base_datasets(DT, X_train, y_train, X_test,  7)    \n",
    "ada_train, ada_test = get_stacking_base_datasets(AdaBoost, X_train, y_train, X_test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original train data: (455, 30) Shape of original test data: (114, 30)\n",
      "Shape of stacking train data: (455, 4) Shape of stacking test data: (114, 4)\n"
     ]
    }
   ],
   "source": [
    "#np.concatenate: Combine multiple arrays by row/col level\n",
    "Final_X_train = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis=1)\n",
    "Final_X_test = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis=1)\n",
    "print('Shape of original train data:',X_train.shape, 'Shape of original test data:',X_test.shape)\n",
    "print('Shape of stacking train data:', Final_X_train.shape, 'Shape of stacking test data:',Final_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final meta model evalutation\n",
      "Confusion Matrix:\n",
      "[[43  1]\n",
      " [ 4 66]]\n",
      "Accuracy: 0.9561, Precision: 0.9851, Recall: 0.9429, f1_score: 0.9635, AUC: 0.9945\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Stacking_final_LR = LogisticRegression(C=10)\n",
    "Stacking_final_LR.fit(Final_X_train, y_train)\n",
    "final_pred = Stacking_final_LR.predict(Final_X_test)\n",
    "final_pred_proba = Stacking_final_LR.predict_proba(Final_X_test)[:,1]\n",
    "\n",
    "from evaluation import get_clf_eval\n",
    "print('Final meta model evalutation')\n",
    "print(get_clf_eval(y_test, final_pred, final_pred_proba))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
